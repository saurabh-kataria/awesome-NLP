# awesome-NLP
Interesting NLP resources

# Representations
1. [Deep Contextualized Word Representations](https://aclanthology.org/N18-1202) (Peters et al., NAACL 2018) - ELMO
2. [Bert: Pre-training of deep bidirectional transformers for language understanding](https://arxiv.org/abs/1810.04805) (Devlin et al., NAACL-HLT 2019) - BERT
3. [Efficient estimation of word representations in vector space](https://arxiv.org/abs/1301.3781) (Mikolov et al., ICLR 2013 ?) - word2vec
4. CoVe
5. GloVe

# Benchmark datasets
1. **Stanford Question Answering Dataset (SQuAD)** for QA - Pranav Rajpurkar, Jian Zhang, Konstantin Lopyrev, and Percy Liang. 2016. Squad: 100, 000+ questions for machine comprehension of text. In EMNLP.
2. **Stanford Natural Language Inference (SNLI) corpus** - Samuel R. Bowman, Gabor Angeli, Christopher Potts, and Christopher D. Manning. 2015. A large annotated corpus for learning natural language inference. In Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing (EMNLP). Association for Computational Linguistics.
3. **OntoNotes benchmark** - Sameer Pradhan, Alessandro Moschitti, Nianwen Xue, Hwee Tou Ng, Anders Bj¨orkelund, Olga Uryupina, Yuchen Zhang, and Zhi Zhong. 2013. Towards robust linguistic analysis using ontonotes. In CoNLL.
4. **CoNLL 2003 NER task** - Erik F. Tjong Kim Sang and Fien De Meulder. 2003. Introduction to the CoNLL-2003 shared task: Language-independent named entity recognition. In CoNLL.
5. **Stanford Sentiment Treebank (SST-5)** - Richard Socher, Alex Perelygin, Jean Y Wu, Jason Chuang, Christopher D Manning, Andrew Y Ng, and Christopher Potts. 2013. Recursive deep models for semantic compositionality over a sentiment treebank. In EMNLP.

# Datasets
1. SemCor 3.0
2. Wall Street Journal portion of the Penn Treebank (PTB)

# Models
1. ESIM sequence model - Qian Chen, Xiao-Dan Zhu, Zhen-Hua Ling, Si Wei, Hui Jiang, and Diana Inkpen. 2017. Enhanced lstm for natural language inference. In ACL.

# Background
1. John D. Lafferty, Andrew McCallum, and Fernando Pereira. 2001. Conditional random ﬁelds: Probabilistic models for segmenting and labeling sequence data. In ICML.

# Tasks
1. Word Sense Disambiguation (WSD)
2. POS tagging task

# Books
1. Speech and Language Processing, Dan Jurafsky and James H. Martin (https://web.stanford.edu/~jurafsky/slp3/)

# Courses
1. NLP coursera course
2. UMass CS685: Advanced Natural Language Processing (Spring 2023) (https://www.youtube.com/watch?v=EJ8H3Ak_afA&list=PLWnsVgP6CzaelCF_jmn5HrpOXzRAPNjWj&index=1)

# Libraries
1. NLTK (https://www.nltk.org/)
